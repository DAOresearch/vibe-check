---
title: Vibe Check
description: Automation and Evaluation framework for Claude Code agents, built on Vitest v3
template: splash
head:
  - tag: meta
    attrs:
      property: og:image
      content: https://daoresearch.github.io/vibe-check/og-images/homepage.png
  - tag: meta
    attrs:
      property: og:image:width
      content: "1200"
  - tag: meta
    attrs:
      property: og:image:height
      content: "630"
  - tag: meta
    attrs:
      name: twitter:card
      content: summary_large_image
  - tag: meta
    attrs:
      name: twitter:image
      content: https://daoresearch.github.io/vibe-check/og-images/homepage.png
hero:
  tagline: Complete documentation for the automation and evaluation platform for Claude Code
  actions:
    - text: Get Started
      link: /getting-started/introduction/
      icon: right-arrow
      variant: primary
    - text: View on GitHub
      link: https://github.com/DAOresearch/vibe-check
      icon: external
---

import { Card, CardGrid } from '@astrojs/starlight/components';

## Quick Navigation

<CardGrid stagger>
  <Card title="üöÄ Getting Started" icon="rocket">
    Tutorials and quick start guides to begin building with Vibe Check

    [Start here ‚Üí](/getting-started/introduction/)
  </Card>

  <Card title="üìñ Guides" icon="open-book">
    How-to guides for common tasks and workflows

    [Browse guides ‚Üí](/guides/)
  </Card>

  <Card title="üß™ Recipes" icon="seti:test-jsx">
    Copy-paste patterns and working examples

    [View recipes ‚Üí](/recipes/)
  </Card>

  <Card title="üìö API Reference" icon="document">
    Complete API documentation

    [API docs ‚Üí](/api/)
  </Card>
</CardGrid>

## What is Vibe Check?

Vibe Check is a **dual-purpose platform** built on Vitest:

### 1. Automation Suite
- Run multi-step agent pipelines
- Orchestrate multiple agents with different tools
- Capture artifacts, metrics, and transcripts
- Get production-grade reporting on every run

### 2. Evaluation Framework
- Benchmark models, prompts, tools, and MCP servers
- Matrix test every configuration in parallel
- Track costs, tokens, duration, and quality
- Enforce quality gates with custom matchers and LLM judges

**Killer feature:** Production-grade **rich terminal + HTML reports** with costs, tokens, timelines, transcripts, todos, and artifacts‚Äîon every run.

## Documentation by Use Case

### I want to automate agent workflows

Build multi-step pipelines, orchestrate agents, and capture artifacts:

1. [First Automation Tutorial](/getting-started/first-automation/) - Build your first pipeline
2. [Building Pipelines](/guides/automation/pipelines/) - Chain agents and pass artifacts
3. [Multi-Agent Orchestration](/guides/automation/orchestration/) - Coordinate multiple agents

### I want to evaluate and benchmark agents

Compare models, track costs, and enforce quality gates:

1. [First Evaluation Tutorial](/getting-started/first-evaluation/) - Benchmark your first agent
2. [Model Benchmarking](/guides/evaluation/benchmarking/) - Compare model performance
3. [Matrix Testing](/guides/evaluation/matrix-testing/) - Test multiple configurations

### I want to look up API details

Complete TypeScript reference with examples:

- [vibeTest](/api/vibetest/) - Test function with fixtures
- [runAgent](/api/runagent/) - Execute agents
- [Custom Matchers](/api/matchers/) - Quality assertions
- [TypeScript Types](/api/types/) - Complete type reference

## Getting Help

- **Bug reports**: [GitHub Issues](https://github.com/DAOresearch/vibe-check/issues)
- **Feature requests**: [GitHub Discussions](https://github.com/DAOresearch/vibe-check/discussions)
- **Questions**: Check [Guides](/guides/) first, then open a discussion

---

Built with ‚ù§Ô∏è for developers who measure twice and ship once.
